
# BERT-Based Multi-Domain Sentiment Analysis Framework

> **Aspect-Category-Opinion-Sentiment (ACOS) Extraction across E-commerce, Hospitality, and Online Education using BERT-mini**

## Overview

This repository contains the official implementation of the paper:

**"A BERT-Based Framework for Multi-Domain Sentiment Analysis on Real-World Review Data"**

We propose a lightweight yet robust sentiment analysis pipeline using a fine-tuned BERT-mini model. It enables aspect-level sentiment extraction across multiple domains â€” including e-commerce, hospitality, and online education â€” with an emphasis on extracting **Aspectâ€“Categoryâ€“Opinionâ€“Sentiment (ACOS)** structures.

---

## Features

- **Multi-domain support** (Amazon, Hotels, Coursera)
- **Lightweight BERT-mini model** for faster inference
- **Aspect-based sentiment analysis** with full ACOS quadruple extraction
- Balanced training via **Stratified K-Fold Cross-Validation**
- Clear metrics: Accuracy, Precision, Recall, Macro/Weighted F1
- Error analysis included to improve domain interpretability

---

## Project Structure

```bash
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ stats/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ checkpoints/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ training.ipynb
â”‚   â””â”€â”€ evaluation.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ evaluate.py
â””â”€â”€ README.md
```

---

## Dataset

We use the **OATS Dataset** curated from real-world review platforms. Each review is labeled with:

- **Sentiment** (`positive`, `neutral`, `negative`)
- **Aspect**
- **Category**
- **Opinion**

| Domain     | Train | Val  | Test | Total  |
|------------|-------|------|------|--------|
| Amazon     | 7360  | 920  | 920  | 9200   |
| Coursera   | 7188  | 898  | 899  | 8985   |
| Hotels     | 7834  | 955  | 980  | 9769   |
| **Total**  | -     | -    | -    | 27,954 |

---

## Model Details

We use a compact version of BERT:

- **Model**: [`prajjwal1/bert-mini`](https://huggingface.co/prajjwal1/bert-mini)
- **Parameters**: 4-layer, 4-head attention, 256 hidden size
- **Fine-tuning Task**: 3-class sentiment classification (`pos`, `neu`, `neg`)

### Training Config

| Parameter         | Value            |
|------------------|------------------|
| Batch size        | 512              |
| Learning rate     | 1e-5             |
| Max epochs        | 50               |
| Early Stopping    | 30 epochs        |
| Optimizer         | AdamW            |
| Loss Function     | CrossEntropyLoss |
| CV folds (k)      | 20               |

---

## Results

| Domain     | Accuracy | Macro-F1 | Neutral F1 |
|------------|----------|----------|-------------|
| Amazon     | 88.4%    | 85.6%    | 24%         |
| Coursera   | 91.1%    | 89.7%    | 28%         |
| Hotels     | 89.2%    | 86.5%    | 26%         |
| **Combined**| **92.3%**| **90.2%**| **27%**     |

---

## Error Analysis

Common error types:
- Missing `aspect` or `opinion` in valid `sentiment` entries
- Ambiguous expressions like _"Love it!"_ or _"Highly recommended."_
- Incomplete phrases (e.g., _"They taste like"_)

---

## ðŸ”® Future Work

- Integrate domain-adaptive pretraining
- Use prompt-tuning for low-resource classes
- Enhance with external knowledge graphs
- Extend to other domains (healthcare, finance)

---

## Citation

```bibtex
@article{huynh2025sentiment,
  title={A BERT-Based Framework for Multi-Domain Sentiment Analysis on Real-World Review Data},
  author={Huynh, Phuong Vi and Tran, Tuyet Hue and Nguyen-Thi, Cam-Tien},
  journal={Preprint},
  year={2025}
}
```

---

## Acknowledgments

- OATS Dataset by Chebolu et al. (2024)
- HuggingFace Transformers
- PyTorch & scikit-learn

---

## Contact

For questions, reach out to:
- **Tuyet Hue Tran**: [23C15027@student.hcmus.edu.vn](mailto:23C15027@student.hcmus.edu.vn)
